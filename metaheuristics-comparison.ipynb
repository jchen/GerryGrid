{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaheuristics for Optimizing Voter Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and importing\n",
    "We first install the necessary packages. If you are using Google Colab (or most other web notebooks), you may install the necessary packages here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitarray\n",
    "!pip install gerrychain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import all necessary packages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "import math\n",
    "import time\n",
    "import statistics\n",
    "from bitarray import bitarray\n",
    "from tqdm import tqdm, trange, tnrange, tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('paper')\n",
    "sns.set(style=\"whitegrid\")\n",
    "from gerrychain import (GeographicPartition, Partition, Graph, MarkovChain,\n",
    "                        proposals, updaters, constraints, accept, Election)\n",
    "from gerrychain.proposals import recom\n",
    "from functools import partial\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with known cases\n",
    "The following tests the various algorithms described with known cases of the grid, specifically, this only works for the $5\\times 5$ case of the grid that we have known data for. It requires importing a large datafile, which is the generated datafile using `grid_search` and `analysis`. We replace the $\\mathsf{Eval}$ function with a deterministic lookup (from the dataframe collected using `grid_search`), and demonstrate how well the algorithms work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(\"df.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(delta, times):\n",
    "    \"\"\"\n",
    "    Replacement for the evaulative function, which\n",
    "    relies on known exhaustive searches. \n",
    "    \"\"\"\n",
    "    output = df.loc[to_N(delta)]['Avg']\n",
    "#     print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Constants\n",
    "We want to define some constants we care about. This basically gives the size of the grid to be $clen \\times rlen$, with $clen$ number of districts with $rlen$ blocks each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clen = 5\n",
    "rlen = 5\n",
    "num_blocks = clen * rlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with BitArrays\n",
    "Voter distributions ($\\Delta$) are stored as BitArrays (or arrays of BitArrays). They are the least computationally intensive and memory taxing way to test these, and allow us to use XOR (^) later instead of int equality (==), which also saves a lot of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_bitarray(n):\n",
    "    \"\"\"\n",
    "    Creates a bit array of length num_blocks with n 'true' values. \n",
    "    \"\"\"\n",
    "    ar = bitarray()\n",
    "    for i in range(n):\n",
    "        ar.append(True)\n",
    "    for i in range(num_blocks - n):\n",
    "        ar.append(False)\n",
    "    return ar\n",
    "\n",
    "def sq_array(ar):\n",
    "    \"\"\"\n",
    "    Converts a bitarray into\n",
    "    a rectangular array\n",
    "    \"\"\"\n",
    "    sq_ar = [bitarray() for i in range(rlen)]\n",
    "    for i in range(rlen):\n",
    "        sq_ar[i] = ar[(clen * i):(clen * (i + 1))]\n",
    "    return sq_ar\n",
    "\n",
    "def get_bitarray(delta):\n",
    "    \"\"\"\n",
    "    Converts a sq/rectangular array\n",
    "    into a bitarray\n",
    "    \"\"\"\n",
    "    output = bitarray()\n",
    "    for row in delta:\n",
    "        for entry in row:\n",
    "            output.append(entry)\n",
    "    return output\n",
    "\n",
    "def print_ar(ar):\n",
    "    \"\"\"\n",
    "    Prints a rectangular array\n",
    "    \"\"\"\n",
    "    print(\"Grid: \")\n",
    "    for row in ar: \n",
    "        rowtext = \"\"\n",
    "        for box in row:\n",
    "            rowtext += \"X\" if box else \"O\"\n",
    "            rowtext += \" \"\n",
    "        print(rowtext)\n",
    "    print()\n",
    "\n",
    "def to_N(delta):\n",
    "    \"\"\"\n",
    "    Stores a rectangular array as some index\n",
    "    (written in base two is the original bitarray)\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for r in reversed(range(rlen)):\n",
    "        for c in reversed(range(clen)):\n",
    "            i = (i << 1) | delta[r][c]\n",
    "    return i\n",
    "\n",
    "def bitarray_to_N(bar):\n",
    "    \"\"\"\n",
    "    The same as above but for a bitarray and not\n",
    "    a rectangular array\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for dig in bar: \n",
    "        i = (i << 1) | dig\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaheuristics/Optimizers\n",
    "We first define some of the number of times we want to run our optimizers (and whether we want it to show progress):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_tqdm = False\n",
    "mcmc_steps = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling\n",
    "The following generates random Deltas and evaluates them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_step(n):\n",
    "    \"\"\"\n",
    "    Gives a random delta with NumH = n\n",
    "    \"\"\"\n",
    "    a = n_bitarray(n)\n",
    "    random.shuffle(a)\n",
    "    return sq_array(a)\n",
    "\n",
    "def random_sample(times, n):\n",
    "    \"\"\"\n",
    "    Evaluates a times number of random_steps\n",
    "    (random deltas) and returns a array of scores\n",
    "    \"\"\"\n",
    "    samp = []\n",
    "    for i in tnrange(times, desc = 'Random Sample', leave = False, disable = disable_tqdm):\n",
    "        step = random_step(n)\n",
    "        samp.append(evaluate(step, mcmc_steps))\n",
    "    return samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shotgun Greedy (Random-Restart Iterated Local Search) Algorithm\n",
    "The following performs a RRILS optimization, which relies on a cellular automata evolutionary algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for Cellular Automata: \n",
    "threshold = 0.6\n",
    "\n",
    "def unhappy(delta):\n",
    "    \"\"\"\n",
    "    returns a tuple of\n",
    "    (list of coords of unhappy tiles, \n",
    "    list of values of unhappy tiles, \n",
    "    Clus, ClusH)\n",
    "    \"\"\"\n",
    "    unhappy_tiles = []\n",
    "    vals = bitarray()\n",
    "    total_con = [0, 0]\n",
    "    con = [0, 0]\n",
    "    for row in range(rlen):\n",
    "        for col in range(clen):\n",
    "            box = delta[row][col]\n",
    "            total_box = 0\n",
    "            same_box = 0\n",
    "            for dx, dy in [(1, 0), (-1, 0), (0, -1), (0, 1)]:\n",
    "                r = row\n",
    "                c = col\n",
    "                nr = r + dx\n",
    "                nc = c + dy\n",
    "                if 0 <= nr < rlen and 0 <= nc < clen:\n",
    "                    total_con[delta[r][c]] += 1\n",
    "                    total_box += 1\n",
    "                    samity = 0 if box ^ delta[nr][nc] else 1\n",
    "                    same_box += samity\n",
    "                    con[delta[r][c]] += samity\n",
    "            if same_box / total_box < threshold:\n",
    "                unhappy_tiles.append((r, c))\n",
    "                vals.append(delta[r][c])\n",
    "    return {'coords': unhappy_tiles, \n",
    "            'vals': vals, \n",
    "            'Clus': (con[0] + con[1]) / (total_con[0] + total_con[1]), \n",
    "            'ClusH': con[1] / total_con[1]}\n",
    "\n",
    "def step(unhappy_coords_shuffled, unhappy_list, delta):\n",
    "    \"\"\"\n",
    "    Makes a step with delta and given values of delta\n",
    "    and returns a new delta\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    ndelta = delta\n",
    "    for r, c in unhappy_coords_shuffled:\n",
    "        ndelta[r][c] = unhappy_list[idx]\n",
    "        idx += 1\n",
    "    return ndelta\n",
    "\n",
    "def greedy_step(delta):\n",
    "    \"\"\"\n",
    "    Runs one evolutionary step, gets rid of the\n",
    "    other parameters in step\n",
    "    \"\"\"\n",
    "    unh = unhappy(delta)\n",
    "    random.shuffle(unh['coords'])\n",
    "    return step(unh['coords'], unh['vals'], delta)\n",
    "\n",
    "def greedy_seq(n, mcmc_steps):\n",
    "    \"\"\"\n",
    "    Runs a greedy sequence multiple times, until\n",
    "    no more meaningful evolutions can be done. \n",
    "    \"\"\"\n",
    "    dt = []\n",
    "    seed = n_bitarray(n)\n",
    "    random.shuffle(seed)\n",
    "    delta = sq_array(seed)\n",
    "    dt.append(evaluate(delta, mcmc_steps))\n",
    "    laststep = to_N(delta)\n",
    "    k = 0\n",
    "    while True:\n",
    "        delta = greedy_step(delta)\n",
    "        k += 1\n",
    "        delta_idx = to_N(delta)\n",
    "        score = evaluate(delta, mcmc_steps)\n",
    "        if delta_idx == laststep:\n",
    "            break\n",
    "        dt.append(score)\n",
    "        laststep = delta_idx\n",
    "    return (dt, k)\n",
    "\n",
    "def shotgun_greedy(k_max, n, mcmc_steps):\n",
    "    \"\"\"\n",
    "    Runs a greedy sequence multiple times, until\n",
    "    it has been evaluated k_max times. \n",
    "    Returns the full dictionary of\n",
    "    {score: N(index)}\n",
    "    \"\"\"\n",
    "    sample = []\n",
    "    times_run = 0\n",
    "    pbar = tqdm_notebook(total=k_max, desc = 'Shotgun Greedy', leave = False, disable = disable_tqdm)\n",
    "    while times_run < k_max: \n",
    "        run = greedy_seq(n, mcmc_steps)\n",
    "        sample += run[0]\n",
    "        times_run += run[1]\n",
    "        pbar.update(run[1])\n",
    "    pbar.close()\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Annealing\n",
    "This is the simulated annealing algorithm, which combines a bit of all the previous algorithms we've used. \n",
    "\n",
    "We first define a probability of acceptance function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_accept(change_e, temp):\n",
    "    try: \n",
    "        return 1 / (1 + math.exp(-change_e / temp))\n",
    "    except OverflowError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`random_accept_thresh` gives the probability that a random state is accepted. \n",
    "\n",
    "`mcmc_steps` gives the number of mcmc steps to perform.\n",
    "\n",
    "`temp_initial` gives the initial temperature.\n",
    "\n",
    "`temp_ratio` is the cooling schedule.\n",
    "\n",
    "`simulated_anneal` runs the annealing steps as documented. \n",
    "\n",
    "`simulated_anneal_random` does simulated annealing but with random progressions (instead of cellular automata progressions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_accept_thresh = 0.4\n",
    "temp_initial = 8\n",
    "temp_ratio = 0.96\n",
    "heating_ratio = 1.1\n",
    "\n",
    "# Simulated Annealing algorithm with greedy chance\n",
    "def simulated_anneal(k_max, n):\n",
    "    \"\"\"\n",
    "    Runs a simulated annealing step\n",
    "    as described in the paper/documentation\n",
    "    \"\"\"\n",
    "    delta = random_step(n)\n",
    "    samp = []\n",
    "    temp = temp_initial\n",
    "    eval_now = evaluate(delta, mcmc_steps)\n",
    "    samp.append(eval_now)\n",
    "    ra_thresh = random_accept_thresh\n",
    "    k = 0\n",
    "    pbar = tqdm_notebook(total=k_max, desc = 'Simulated Anneal', leave = False, disable = disable_tqdm)\n",
    "    while k < k_max:\n",
    "        delta_n = greedy_step(delta)\n",
    "        eval_new = evaluate(delta_n, mcmc_steps)\n",
    "        samp.append(eval_new)\n",
    "        k += 1\n",
    "        pbar.update(1)\n",
    "        change_e = eval_new - eval_now\n",
    "        # we can also give the change as a proportion, which makes hyperparameter optimization\n",
    "        # better for generalization: \n",
    "        prop_change_e = change_e / clen\n",
    "        if change_e > 0 or prob_accept(prop_change_e, temp) > random.uniform(0, 1):\n",
    "#             print('Accept')\n",
    "            delta = delta_n\n",
    "            eval_now = eval_new\n",
    "            temp = temp * temp_ratio\n",
    "        else:\n",
    "            delta_rand_n = random_step(n)\n",
    "            eval_rand_new = evaluate(delta_rand_n, mcmc_steps)\n",
    "            samp.append(eval_rand_new)\n",
    "            k += 1\n",
    "            pbar.update(1)\n",
    "            change_rand_e = eval_rand_new - eval_now\n",
    "            prop_random_change_e = change_rand_e / clen\n",
    "            if change_e > 0 or prob_accept(prop_random_change_e, temp) > random.uniform(0, 1):\n",
    "#                 print('Accept')\n",
    "                delta = delta_rand_n\n",
    "                eval_now = eval_rand_new\n",
    "                temp = temp * temp_ratio\n",
    "            else:\n",
    "                temp = temp * heating_ratio\n",
    "    pbar.close()\n",
    "    return samp\n",
    "\n",
    "def random_swap_step(delta, n):\n",
    "    delta_ba = get_bitarray(delta)\n",
    "    delta_n = delta_ba\n",
    "    change_ar = n_bitarray(n)\n",
    "    random.shuffle(change_ar)\n",
    "    change_vals = bitarray()\n",
    "    idx = 0\n",
    "    for i in change_ar:\n",
    "        if i:\n",
    "            change_vals.append(delta_ba[idx])\n",
    "        idx += 1\n",
    "    random.shuffle(change_vals)\n",
    "    in_idx = 0\n",
    "    idx = 0\n",
    "    for i in change_ar:\n",
    "        if i:\n",
    "            delta_n[in_idx] = change_vals[idx]\n",
    "            idx += 1\n",
    "        in_idx += 1\n",
    "    return sq_array(delta_n)\n",
    "\n",
    "step_swap_size = 4\n",
    "\n",
    "# After testing for various hyperparameters, this is what we found to be the best experimentally: \n",
    "temp_initial_random = 1\n",
    "temp_ratio_random = 0.8\n",
    "\n",
    "# Simulated Annealing algorithm with random neighbour step\n",
    "def simulated_anneal_random(k_max, n):\n",
    "    \"\"\"\n",
    "    Runs a simulated annealing step\n",
    "    as described in the paper/documentation\n",
    "    \"\"\"\n",
    "    delta = random_step(n)\n",
    "    samp = []\n",
    "    temp = temp_initial_random\n",
    "    eval_now = evaluate(delta, mcmc_steps)\n",
    "    ra_thresh = random_accept_thresh\n",
    "    k = 0\n",
    "    pbar = tqdm_notebook(total=k_max, desc = 'Simulated Anneal', leave = False, disable = disable_tqdm)\n",
    "    while k < k_max:\n",
    "        samp.append(eval_now)\n",
    "        delta_n = random_swap_step(delta, step_swap_size)\n",
    "        eval_new = evaluate(delta_n, mcmc_steps)\n",
    "        k += 1\n",
    "        pbar.update(1)\n",
    "        change_e = eval_new - eval_now\n",
    "        # we can also give the change as a proportion, which makes hyperparameter optimization\n",
    "        # better for generalization (grid size does not affect what hyperparams do): \n",
    "        prop_change_e = change_e / clen\n",
    "        if change_e > 0 or prob_accept(prop_change_e, temp) > random.uniform(0, 1):\n",
    "#             Testing: \n",
    "#             print(eval_new)\n",
    "#             print('Accept')\n",
    "            delta = delta_n\n",
    "            eval_now = eval_new\n",
    "            temp = temp * temp_ratio_random\n",
    "    pbar.close()\n",
    "    return samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mult_simulated_anneal` runs simulated anneal multiple times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k_\\mathrm{max}$ versus outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare our algorithms by seeing how fast they converge to the maximum given a specific $k_\\mathrm{max}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loops through all the algorithms for varying $k_\\mathrm{max}$ values and logs it to datatables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_tqdm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comparison(numH, samp_size, k_max):\n",
    "    full_dt_singleruns = []\n",
    "\n",
    "    for i in tnrange(samp_size, desc = \"Random\"):\n",
    "        run = random_sample(k_max, numH)\n",
    "        k_current = 1\n",
    "        max = 0\n",
    "        for score in run: \n",
    "            if k_current == k_max: \n",
    "                break\n",
    "            if score > max:\n",
    "                max = score\n",
    "            full_dt_singleruns.append([k_current, max, \"Random\"])\n",
    "            k_current += 1\n",
    "\n",
    "\n",
    "    for i in tnrange(samp_size, desc = \"RRILS\"):\n",
    "        run = shotgun_greedy(k_max, numH, 1)\n",
    "        k_current = 1\n",
    "        max = 0\n",
    "        for score in run: \n",
    "            if k_current == k_max: \n",
    "                break\n",
    "            if score > max:\n",
    "                max = score\n",
    "            full_dt_singleruns.append([k_current, max, \"RRILS\"])\n",
    "            k_current += 1\n",
    "\n",
    "\n",
    "    for i in tnrange(samp_size, desc = \"S.A.\"):\n",
    "        run = simulated_anneal(k_max, numH)\n",
    "        k_current = 1\n",
    "        max = 0\n",
    "        for score in run: \n",
    "            if k_current == k_max: \n",
    "                break\n",
    "            if score > max:\n",
    "                max = score\n",
    "            full_dt_singleruns.append([k_current, max, \"S.A.\"])\n",
    "            k_current += 1\n",
    "\n",
    "\n",
    "    for i in tnrange(samp_size, desc = \"S.A. (Random)\"):\n",
    "        run = simulated_anneal_random(k_max, numH)\n",
    "        k_current = 1\n",
    "        max = 0\n",
    "        for score in run: \n",
    "            if k_current == k_max: \n",
    "                break\n",
    "            if score > max:\n",
    "                max = score\n",
    "            full_dt_singleruns.append([k_current, max, \"S.A. (Random)\"])\n",
    "            k_current += 1\n",
    "\n",
    "    actual_max = df.loc[df[\"NumH\"] == numH].nlargest(1, \"Avg\")[\"Avg\"].item()\n",
    "\n",
    "    full_dt_singleruns.append([0, actual_max, \"Maximum\"])\n",
    "    full_dt_singleruns.append([k_max, actual_max, \"Maximum\"])\n",
    "\n",
    "\n",
    "    full_df = pd.DataFrame(full_dt_singleruns, columns = (\"k_max\", \"runmax\", \"Method\"))\n",
    "    full_df.to_csv(\"k_max_vs_outcome-samp_size\" + str(samp_size) + \"-numH\" + str(numH) + \"-k_max\" + str(k_max) + \".csv\")\n",
    "\n",
    "    fig = plt.figure(figsize=(8.5, 6.5), dpi=300)\n",
    "    ax = sns.lineplot(x=\"k_max\", y=\"runmax\", style=\"Method\", hue=\"Method\", ci=100, dashes = {'Maximum': (1, 2), 'Random': '', 'S.A.': '', 'S.A. (Random)': '', 'RRILS': ''}, data = full_df)\n",
    "    ax.set(xlabel='$k_\\mathrm{max}$', ylabel='Outcome')\n",
    "    ax.set_title('$k_\\mathrm{max}$ versus Outcome for Varying Algorithms, $\\mathsf{NumH} = ' + str(numH) + '$')\n",
    "\n",
    "    plt.savefig(\"algorithm-comparison-samp_size\" + str(samp_size) + \"-numH\" + str(numH) + \"-k_max\" + str(k_max) + \".pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_comparison(9, 10000, 1000)\n",
    "run_comparison(10, 10000, 1000)\n",
    "run_comparison(11, 10000, 1000)\n",
    "run_comparison(12, 10000, 1000)\n",
    "run_comparison(5, 10000, 1000)\n",
    "run_comparison(4, 10000, 1000)\n",
    "run_comparison(3, 10000, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
