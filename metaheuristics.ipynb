{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaheuristics for Optimizing Voter Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and importing\n",
    "We first install the necessary packages. If you are using Google Colab (or most other web notebooks), you may install the necessary packages here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitarray\n",
    "!pip install gerrychain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import all necessary packages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gerrychain.random import random\n",
    "import math\n",
    "import time\n",
    "import statistics\n",
    "from bitarray import bitarray\n",
    "from gerrychain import Graph, Partition, Election, grid, MarkovChain\n",
    "from gerrychain.constraints import single_flip_contiguous, contiguous\n",
    "from gerrychain.proposals import propose_random_flip, propose_chunk_flip, spectral_recom, recom\n",
    "from gerrychain.accept import always_accept\n",
    "from gerrychain.tree import recursive_tree_part\n",
    "from tqdm import tqdm, trange, tnrange, tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('paper')\n",
    "sns.set(style=\"whitegrid\")\n",
    "from gerrychain import (GeographicPartition, Partition, Graph, MarkovChain,\n",
    "                        proposals, updaters, constraints, accept, Election)\n",
    "from gerrychain.proposals import recom\n",
    "from functools import partial\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Constants\n",
    "We want to define some constants we care about. This basically gives the size of the grid to be $clen \\times rlen$, with $clen$ number of districts with $rlen$ blocks each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clen = 5\n",
    "rlen = 5\n",
    "num_blocks = clen * rlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with BitArrays\n",
    "Voter distributions ($\\Delta$) are stored as BitArrays (or arrays of BitArrays). They are the least computationally intensive and memory taxing way to test these, and allow us to use XOR (^) later instead of int equality (==), which also saves a lot of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_bitarray(n):\n",
    "    \"\"\"\n",
    "    Creates a bit array of length num_blocks with n 'true' values. \n",
    "    \"\"\"\n",
    "    ar = bitarray()\n",
    "    for i in range(n):\n",
    "        ar.append(True)\n",
    "    for i in range(num_blocks - n):\n",
    "        ar.append(False)\n",
    "    return ar\n",
    "\n",
    "def sq_array(ar):\n",
    "    \"\"\"\n",
    "    Converts a bitarray into\n",
    "    a rectangular array\n",
    "    \"\"\"\n",
    "    sq_ar = [bitarray() for i in range(rlen)]\n",
    "    for i in range(rlen):\n",
    "        sq_ar[i] = ar[(clen * i):(clen * (i + 1))]\n",
    "    return sq_ar\n",
    "\n",
    "def get_bitarray(delta):\n",
    "    \"\"\"\n",
    "    Converts a sq/rectangular array\n",
    "    into a bitarray\n",
    "    \"\"\"\n",
    "    output = bitarray()\n",
    "    for row in delta:\n",
    "        for entry in row:\n",
    "            output.append(entry)\n",
    "    return output\n",
    "\n",
    "def print_ar(ar):\n",
    "    \"\"\"\n",
    "    Prints a rectangular array\n",
    "    \"\"\"\n",
    "    print(\"Grid: \")\n",
    "    for row in ar: \n",
    "        rowtext = \"\"\n",
    "        for box in row:\n",
    "            rowtext += \"X\" if box else \"O\"\n",
    "            rowtext += \" \"\n",
    "        print(rowtext)\n",
    "    print()\n",
    "\n",
    "def to_N(delta):\n",
    "    \"\"\"\n",
    "    Stores a rectangular array as some index\n",
    "    (written in base two is the original bitarray)\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for r in reversed(range(rlen)):\n",
    "        for c in reversed(range(clen)):\n",
    "            i = (i << 1) | delta[r][c]\n",
    "    return i\n",
    "\n",
    "def bitarray_to_N(bar):\n",
    "    \"\"\"\n",
    "    The same as above but for a bitarray and not\n",
    "    a rectangular array\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for dig in bar: \n",
    "        i = (i << 1) | dig\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GerryChains\n",
    "Working with MGGG's GerryChain to create functions to run MCMC (The Eval function). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So sometimes there's this fatal crash when trying to generate a base partition to begin the MCMC on, which is really frustrating. I can't seem to figure out what's causing it. So, I'll generate a predefined array of partitions to start with and every time, the MCMC algorithm picks one randomly. This might be due to some memory leak or flooding from the GerryChain algorithm. For the moment, it's as good as generating a new one every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignment_delta(clen, rlen):\n",
    "    asgmt_grid = grid.Grid((clen, rlen))\n",
    "    asgmt = recursive_tree_part(graph = asgmt_grid.graph, \n",
    "                        parts = range(clen), \n",
    "                        pop_target = rlen, \n",
    "                        pop_col = 'area', \n",
    "                        epsilon = 0.02,\n",
    "                        node_repeats = 1)\n",
    "    return asgmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code **once** and only once. It should be able to load several 'assignments' into an array of different initial partitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = []\n",
    "for i in range(128):\n",
    "    partitions.append(assignment_delta(clen, rlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sets up the GerryChain MCMC that we use as our $\\mathsf{Eval}$ function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_arrays(delta):\n",
    "    \"\"\"\n",
    "    Takes a BitArray Delta (rectangular grid), \n",
    "    and outputs a dictionary of which coordinates\n",
    "    contain hearts tiles. \n",
    "    \"\"\"\n",
    "    hearts_array = {}\n",
    "    unhearts_array = {}\n",
    "    for row in range(rlen):\n",
    "        for col in range(clen):\n",
    "            if delta[row][col]:\n",
    "                hearts_array[(col, row)] = 1\n",
    "                unhearts_array[(col, row)] = 0\n",
    "            else: \n",
    "                hearts_array[(col, row)] = 0\n",
    "                unhearts_array[(col, row)] = 1\n",
    "    return {'hearts': hearts_array, 'unhearts': unhearts_array}\n",
    "\n",
    "def mcmc(delta, steps):\n",
    "    \"\"\"\n",
    "    Runs a step number of MCMC on a given delta. \n",
    "    Returns the distribution of seats won. \n",
    "    \"\"\"\n",
    "    vote_list = vote_arrays(delta)\n",
    "    hearts_list = vote_list['hearts']\n",
    "    unhearts_list = vote_list['unhearts']\n",
    "\n",
    "    election = Election(\"Elc\", \n",
    "                        {\"Hearts\": hearts_list, \n",
    "                         \"Unhearts\": unhearts_list}\n",
    "    )\n",
    "\n",
    "    ideal_population = rlen\n",
    "\n",
    "    proposal = partial(recom,\n",
    "                       pop_col='area',\n",
    "                       pop_target=ideal_population,\n",
    "                       epsilon=0.01,\n",
    "                       node_repeats=2\n",
    "                      )\n",
    "\n",
    "    # asgmt = assignment_delta(clen, rlen)\n",
    "\n",
    "    grd = grid.Grid(dimensions = (clen, rlen), \n",
    "                    assignment = partitions[random.randint(0, 127)], \n",
    "                  # Above is where asgmt would have gone, but due to the unknown bug \n",
    "                  # it just searches a pregenerated array of possibilities. \n",
    "                    updaters = {\"Elc\": election})\n",
    "\n",
    "    chain = MarkovChain(\n",
    "        proposal=proposal,\n",
    "        constraints=[contiguous],\n",
    "        accept=always_accept,\n",
    "        initial_state=grd,\n",
    "        total_steps=steps\n",
    "    )\n",
    "\n",
    "    results = [0 for i in range(rlen + 1)]\n",
    "    for partition in chain:\n",
    "        results[partition[\"Elc\"].wins(\"Hearts\")] += 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate(delta, times):\n",
    "    \"\"\"\n",
    "    Evaluates a delta a number of times, and returns the average\n",
    "    \"\"\"\n",
    "    result = mcmc(delta, times)\n",
    "    n = 0\n",
    "    sum = 0\n",
    "    for idx in range(len(result)):\n",
    "        num_idx = result[idx]\n",
    "        n += num_idx\n",
    "        sum += num_idx * idx\n",
    "    output = sum / n\n",
    "    print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaheuristics/Optimizers\n",
    "We first define some of the number of times we want to run our optimizers (and whether we want it to show progress):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_step(n):\n",
    "    \"\"\"\n",
    "    Gives a random delta with NumH = n\n",
    "    \"\"\"\n",
    "    a = n_bitarray(n)\n",
    "    random.shuffle(a)\n",
    "    return sq_array(a)\n",
    "\n",
    "def random_sample(times, n):\n",
    "    \"\"\"\n",
    "    Evaluates a times number of random_steps\n",
    "    (random deltas) and returns a dictionary\n",
    "    formatted {score: N(index)}\n",
    "    \"\"\"\n",
    "    samp = {}\n",
    "    for i in tnrange(times, desc = 'Random Sample', leave = False, disable = disable_tqdm):\n",
    "        step = random_step(n)\n",
    "        samp[evaluate(step, mcmc_steps)] = to_N(step)\n",
    "    return samp\n",
    "\n",
    "def mult_random_sample(times, k_max, n):\n",
    "    \"\"\"\n",
    "    Does mult_random_sample times times and\n",
    "    gives a list of all the maximums of the\n",
    "    random_sample (since that is what we're\n",
    "    interested in)\n",
    "    \"\"\"\n",
    "    maxs = []\n",
    "    for i in tnrange(times, desc = 'Multiple Random Sample', disable = disable_tqdm):\n",
    "        run = random_sample(k_max, n)\n",
    "        maxs.append((max(run), run[max(run)]))\n",
    "    return maxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling\n",
    "The following generates random Deltas and evaluates them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_step(n):\n",
    "    \"\"\"\n",
    "    Gives a random delta with NumH = n\n",
    "    \"\"\"\n",
    "    a = n_bitarray(n)\n",
    "    random.shuffle(a)\n",
    "    return sq_array(a)\n",
    "\n",
    "def random_sample(times, n):\n",
    "    \"\"\"\n",
    "    Evaluates a times number of random_steps\n",
    "    (random deltas) and returns a dictionary\n",
    "    formatted {score: N(index)}\n",
    "    \"\"\"\n",
    "    samp = {}\n",
    "    for i in tnrange(times, desc = 'Random Sample', leave = False, disable = disable_tqdm):\n",
    "        step = random_step(n)\n",
    "        samp[evaluate(step, mcmc_steps)] = to_N(step)\n",
    "    return samp\n",
    "\n",
    "def mult_random_sample(times, k_max, n):\n",
    "    \"\"\"\n",
    "    Does mult_random_sample times times and\n",
    "    gives a list of all the maximums of the\n",
    "    random_sample (since that is what we're\n",
    "    interested in)\n",
    "    \"\"\"\n",
    "    maxs = []\n",
    "    for i in tnrange(times, desc = 'Multiple Random Sample', disable = disable_tqdm):\n",
    "        run = random_sample(k_max, n)\n",
    "        maxs.append((max(run), run[max(run)]))\n",
    "    return maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = mult_random_sample(samp_size, 200, 10)\n",
    "for run in samp: \n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shotgun Greedy (Random-Restart Iterated Local Search) Algorithm\n",
    "The following performs a RRILS optimization, which relies on a cellular automata evolutionary algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for Cellular Automata: \n",
    "threshold = 0.6\n",
    "\n",
    "def unhappy(delta):\n",
    "    \"\"\"\n",
    "    returns a tuple of\n",
    "    (list of coords of unhappy tiles, \n",
    "    list of values of unhappy tiles, \n",
    "    Clus, ClusH)\n",
    "    \"\"\"\n",
    "    unhappy_tiles = []\n",
    "    vals = bitarray()\n",
    "    total_con = [0, 0]\n",
    "    con = [0, 0]\n",
    "    for row in range(rlen):\n",
    "        for col in range(clen):\n",
    "            box = delta[row][col]\n",
    "            total_box = 0\n",
    "            same_box = 0\n",
    "            for dx, dy in [(1, 0), (-1, 0), (0, -1), (0, 1)]:\n",
    "                r = row\n",
    "                c = col\n",
    "                nr = r + dx\n",
    "                nc = c + dy\n",
    "                if 0 <= nr < rlen and 0 <= nc < clen:\n",
    "                    total_con[delta[r][c]] += 1\n",
    "                    total_box += 1\n",
    "                    samity = 0 if box ^ delta[nr][nc] else 1\n",
    "                    same_box += samity\n",
    "                    con[delta[r][c]] += samity\n",
    "            if same_box / total_box < threshold:\n",
    "                unhappy_tiles.append((r, c))\n",
    "                vals.append(delta[r][c])\n",
    "    return {'coords': unhappy_tiles, \n",
    "            'vals': vals, \n",
    "            'Clus': (con[0] + con[1]) / (total_con[0] + total_con[1]), \n",
    "            'ClusH': con[1] / total_con[1]}\n",
    "\n",
    "def step(unhappy_coords_shuffled, unhappy_list, delta):\n",
    "    \"\"\"\n",
    "    Makes a step with delta and given values of delta\n",
    "    and returns a new delta\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    ndelta = delta\n",
    "    for r, c in unhappy_coords_shuffled:\n",
    "        ndelta[r][c] = unhappy_list[idx]\n",
    "        idx += 1\n",
    "    return ndelta\n",
    "\n",
    "def greedy_step(delta):\n",
    "    \"\"\"\n",
    "    Runs one evolutionary step, gets rid of the\n",
    "    other parameters in step\n",
    "    \"\"\"\n",
    "    unh = unhappy(delta)\n",
    "    random.shuffle(unh['coords'])\n",
    "    return step(unh['coords'], unh['vals'], delta)\n",
    "\n",
    "def greedy_seq(n, mcmc_steps):\n",
    "    \"\"\"\n",
    "    Runs a greedy sequence multiple times, until\n",
    "    no more meaningful evolutions can be done. \n",
    "    \"\"\"\n",
    "    dt = {}\n",
    "    seed = n_bitarray(n)\n",
    "    random.shuffle(seed)\n",
    "    delta = sq_array(seed)\n",
    "    dt[evaluate(delta, mcmc_steps)] = to_N(delta)\n",
    "    laststep = to_N(delta)\n",
    "    k = 0\n",
    "    while True:\n",
    "        delta = greedy_step(delta)\n",
    "        k += 1\n",
    "        delta_idx = to_N(delta)\n",
    "        score = evaluate(delta, mcmc_steps)\n",
    "        if delta_idx == laststep:\n",
    "            break\n",
    "        dt[score] = delta_idx\n",
    "        laststep = delta_idx\n",
    "    return (dt, k)\n",
    "\n",
    "def shotgun_greedy(k_max, n, mcmc_steps):\n",
    "    \"\"\"\n",
    "    Runs a greedy sequence multiple times, until\n",
    "    it has been evaluated k_max times. \n",
    "    Returns the full dictionary of\n",
    "    {score: N(index)}\n",
    "    \"\"\"\n",
    "    sample = {}\n",
    "    times_run = 0\n",
    "    pbar = tqdm_notebook(total=k_max, desc = 'Shotgun Greedy', leave = False, disable = disable_tqdm)\n",
    "    while times_run < k_max: \n",
    "        run = greedy_seq(n, mcmc_steps)\n",
    "        sample.update(run[0])\n",
    "        times_run += run[1]\n",
    "        pbar.update(run[1])\n",
    "    pbar.close()\n",
    "    return sample\n",
    "\n",
    "def mult_shotgun_greedy(times, k_max, n, mcmc_steps):\n",
    "    \"\"\"\n",
    "    Runs shotgun_greedy multiple times, \n",
    "    and returns a list of\n",
    "    (max, N that gives the max)\n",
    "    \"\"\"\n",
    "    maxs = []\n",
    "    for i in tnrange(times, desc = 'Multiple Shotgun Greedy', disable = disable_tqdm):\n",
    "        run = shotgun_greedy(k_max, n, mcmc_steps)\n",
    "        maxs.append((max(run), run[max(run)]))\n",
    "    return maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = mult_shotgun_greedy(samp_size, 200, 10, mcmc_steps)\n",
    "for run in samp: \n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Annealing\n",
    "This is the simulated annealing algorithm, which combines a bit of all the previous algorithms we've used. \n",
    "\n",
    "We first define a probability of acceptance function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_accept(change_e, temp):\n",
    "    try: \n",
    "        return 1 / (1 + math.exp(-change_e / temp))\n",
    "    except OverflowError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`random_accept_thresh` gives the probability that a random state is accepted. \n",
    "\n",
    "`mcmc_steps` gives the number of mcmc steps to perform.\n",
    "\n",
    "`temp_initial` gives the initial temperature.\n",
    "\n",
    "`temp_ratio` is the cooling schedule.\n",
    "\n",
    "`simulated_anneal` runs the annealing steps as documented. \n",
    "\n",
    "`simulated_anneal_random` does simulated annealing but with random progressions (instead of cellular automata progressions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_accept_thresh = 0.4\n",
    "temp_initial = 8\n",
    "temp_ratio = 0.96\n",
    "heating_ratio = 1.1\n",
    "\n",
    "# Simulated Annealing algorithm with greedy chance\n",
    "def simulated_anneal(k_max, n):\n",
    "    \"\"\"\n",
    "    Runs a simulated annealing step\n",
    "    as described in the paper/documentation\n",
    "    \"\"\"\n",
    "    delta = random_step(n)\n",
    "    samp = {}\n",
    "    temp = temp_initial\n",
    "    eval_now = evaluate(delta, mcmc_steps)\n",
    "    ra_thresh = random_accept_thresh\n",
    "    k = 0\n",
    "    pbar = tqdm_notebook(total=k_max, desc = 'Simulated Anneal', leave = False, disable = disable_tqdm)\n",
    "    while k < k_max:\n",
    "        samp[eval_now] = to_N(delta)\n",
    "        delta_n = greedy_step(delta)\n",
    "        eval_new = evaluate(delta_n, mcmc_steps)\n",
    "        k += 1\n",
    "        pbar.update(1)\n",
    "        change_e = eval_new - eval_now\n",
    "        # we can also give the change as a proportion, which makes hyperparameter optimization\n",
    "        # better for generalization: \n",
    "        prop_change_e = change_e / clen\n",
    "        if change_e > 0 or prob_accept(prop_change_e, temp) > random.uniform(0, 1):\n",
    "#             print('Accept')\n",
    "            delta = delta_n\n",
    "            eval_now = eval_new\n",
    "            temp = temp * temp_ratio\n",
    "        else:\n",
    "            delta_rand_n = random_step(n)\n",
    "            eval_rand_new = evaluate(delta_rand_n, mcmc_steps)\n",
    "            k += 1\n",
    "            pbar.update(1)\n",
    "            change_rand_e = eval_rand_new - eval_now\n",
    "            prop_random_change_e = change_rand_e / clen\n",
    "            if change_e > 0 or prob_accept(prop_random_change_e, temp) > random.uniform(0, 1):\n",
    "#                 print('Accept')\n",
    "                delta = delta_rand_n\n",
    "                eval_now = eval_rand_new\n",
    "                temp = temp * temp_ratio\n",
    "            else:\n",
    "                temp = temp * heating_ratio\n",
    "    pbar.close()\n",
    "    return samp\n",
    "\n",
    "def random_swap_step(delta, n):\n",
    "    delta_ba = get_bitarray(delta)\n",
    "    delta_n = delta_ba\n",
    "    change_ar = n_bitarray(n)\n",
    "    random.shuffle(change_ar)\n",
    "    change_vals = bitarray()\n",
    "    idx = 0\n",
    "    for i in change_ar:\n",
    "        if i:\n",
    "            change_vals.append(delta_ba[idx])\n",
    "        idx += 1\n",
    "    random.shuffle(change_vals)\n",
    "    in_idx = 0\n",
    "    idx = 0\n",
    "    for i in change_ar:\n",
    "        if i:\n",
    "            delta_n[in_idx] = change_vals[idx]\n",
    "            idx += 1\n",
    "        in_idx += 1\n",
    "    return sq_array(delta_n)\n",
    "\n",
    "step_swap_size = 4\n",
    "\n",
    "# After testing for various hyperparameters, this is what we found to be the best experimentally: \n",
    "temp_initial_random = 1\n",
    "temp_ratio_random = 0.8\n",
    "\n",
    "# Simulated Annealing algorithm with random neighbour step\n",
    "def simulated_anneal_random(k_max, n):\n",
    "    \"\"\"\n",
    "    Runs a simulated annealing step\n",
    "    as described in the paper/documentation\n",
    "    \"\"\"\n",
    "    delta = random_step(n)\n",
    "    samp = {}\n",
    "    temp = temp_initial_random\n",
    "    eval_now = evaluate(delta, mcmc_steps)\n",
    "    ra_thresh = random_accept_thresh\n",
    "    k = 0\n",
    "    pbar = tqdm_notebook(total=k_max, desc = 'Simulated Anneal', leave = False, disable = disable_tqdm)\n",
    "    while k < k_max:\n",
    "        samp[eval_now] = to_N(delta)\n",
    "        delta_n = random_swap_step(delta, step_swap_size)\n",
    "        eval_new = evaluate(delta_n, mcmc_steps)\n",
    "        k += 1\n",
    "        pbar.update(1)\n",
    "        change_e = eval_new - eval_now\n",
    "        # we can also give the change as a proportion, which makes hyperparameter optimization\n",
    "        # better for generalization (grid size does not affect what hyperparams do): \n",
    "        prop_change_e = change_e / clen\n",
    "        if change_e > 0 or prob_accept(prop_change_e, temp) > random.uniform(0, 1):\n",
    "#             Testing: \n",
    "#             print(eval_new)\n",
    "#             print('Accept')\n",
    "            delta = delta_n\n",
    "            eval_now = eval_new\n",
    "            temp = temp * temp_ratio_random\n",
    "    pbar.close()\n",
    "    return samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mult_simulated_anneal` runs simulated anneal multiple times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_run = True\n",
    "\n",
    "def mult_simulated_anneal(times, k_max, n):\n",
    "    \"\"\"\n",
    "    Runs simulated annealing multiple times\n",
    "    \"\"\"\n",
    "    maxs = []\n",
    "    for i in tnrange(times, desc = 'Multiple S.A.', leave = single_run, disable = disable_tqdm):\n",
    "        run = simulated_anneal(k_max, n)\n",
    "        maxs.append((max(run), run[max(run)]))\n",
    "    return maxs\n",
    "\n",
    "def mult_simulated_anneal_random(times, k_max, n):\n",
    "    \"\"\"\n",
    "    Runs random simulated annealing multiple times\n",
    "    \"\"\"\n",
    "    maxs = []\n",
    "    for i in tnrange(times, desc = 'Multiple S.A. Random', leave = single_run, disable = disable_tqdm):\n",
    "        run = simulated_anneal_random(k_max, n)\n",
    "        maxs.append((max(run), run[max(run)]))\n",
    "    return maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = mult_simulated_anneal_random(samp_size, 200, 10)\n",
    "for run in samp: \n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with known cases\n",
    "The following tests the various algorithms described with known cases of the grid, specifically, this only works for the $5\\times 5$ case of the grid that we have known data for. It requires importing a large datafile, which is the generated datafile using `grid_search` and `analysis`. We replace the $\\mathsf{Eval}$ function with a deterministic lookup (from the dataframe collected using `grid_search`), and demonstrate how well the algorithms work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(\"df.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(delta, times):\n",
    "    \"\"\"\n",
    "    Replacement for the evaulative function, which\n",
    "    relies on known exhaustive searches. \n",
    "    \"\"\"\n",
    "    output = df.loc[to_N(delta)]['Avg']\n",
    "#     print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minority Populations (Allows us to use greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following runs a multiple random sample and outputs the average maximum outcome of the optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = mult_random_sample(samp_size, 300, 10)\n",
    "sum = 0\n",
    "for run in samp: \n",
    "    sum += run[0]\n",
    "#     print(run)\n",
    "runavg = sum / len(samp)\n",
    "print()\n",
    "print(runavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following runs a multiple RRILS and outputs the average maximum outcome of the optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = mult_shotgun_greedy(samp_size, 300, 10, mcmc_steps)\n",
    "sum = 0\n",
    "for run in samp: \n",
    "    sum += run[0]\n",
    "#     print(run)\n",
    "runavg = sum / len(samp)\n",
    "print()\n",
    "print(runavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following runs a multiple simulated anneal and outputs the average maximum outcome of the optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_run = True\n",
    "temp_initial = 10\n",
    "temp_rate = 0.7\n",
    "threshold = 0.6\n",
    "samp = mult_simulated_anneal(samp_size, 300, 10)\n",
    "sum = 0\n",
    "for run in samp: \n",
    "    sum += run[0]\n",
    "#     print(run)\n",
    "runavg = sum / len(samp)\n",
    "print()\n",
    "print(runavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following runs a multiple non-greedy simulated anneal and outputs the average maximum outcome of the optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_run = True\n",
    "temp_initial = 10\n",
    "temp_rate = 0.7\n",
    "threshold = 0.6\n",
    "samp = mult_simulated_anneal_random(samp_size, 300, 10)\n",
    "sum = 0\n",
    "for run in samp: \n",
    "    sum += run[0]\n",
    "#     print(run)\n",
    "runavg = sum / len(samp)\n",
    "print()\n",
    "print(runavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Populations (Random and modified simulated annealing only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = mult_random_sample(samp_size, 400, 16)\n",
    "sum = 0\n",
    "for run in samp: \n",
    "    sum += run[0]\n",
    "#     print(run)\n",
    "runavg = sum / len(samp)\n",
    "print()\n",
    "print(runavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_run = True\n",
    "temp_initial = 10\n",
    "temp_rate = 0.7\n",
    "threshold = 0.6\n",
    "samp = mult_simulated_anneal_random(samp_size, 400, 16)\n",
    "sum = 0\n",
    "for run in samp: \n",
    "    sum += run[0]\n",
    "#     print(run)\n",
    "runavg = sum / len(samp)\n",
    "print()\n",
    "print(runavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Minimum time to reach certain percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_size = 500\n",
    "mcmc_steps = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions finds the minimum value of $k_\\mathrm{max}$ that gives a result that is as good as `bound`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mintime_mult_random_sample(n, bound):\n",
    "    k_max_required = 1\n",
    "    while True: \n",
    "        samp = mult_random_sample(samp_size, k_max_required, n)\n",
    "        sum = 0\n",
    "        for run in samp: \n",
    "            sum += run[0]\n",
    "        runavg = sum / len(samp)\n",
    "        print(runavg)\n",
    "        if runavg > bound: \n",
    "            return k_max_required\n",
    "        else: \n",
    "            k_max_required += 10\n",
    "\n",
    "\n",
    "mintime_mult_random_sample(10, 2.223665)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mintime_mult_greedy_sample(n, bound):\n",
    "    k_max_required = 1\n",
    "    while True: \n",
    "        samp = mult_shotgun_greedy(samp_size, k_max_required, n, mcmc_steps)\n",
    "        sum = 0\n",
    "        for run in samp: \n",
    "            sum += run[0]\n",
    "        runavg = sum / len(samp)\n",
    "        print(runavg)\n",
    "        if runavg > bound: \n",
    "            return k_max_required\n",
    "        else: \n",
    "            k_max_required += 50\n",
    "\n",
    "\n",
    "mintime_mult_greedy_sample(10, 2.280829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mintime_mult_sa_sample(n, bound):\n",
    "    k_max_required = 1\n",
    "    while True: \n",
    "        samp = mult_simulated_anneal(samp_size, k_max_required, n)\n",
    "        sum = 0\n",
    "        for run in samp: \n",
    "            sum += run[0]\n",
    "        runavg = sum / len(samp)\n",
    "        print(runavg)\n",
    "        if runavg > bound: \n",
    "            return k_max_required\n",
    "        else: \n",
    "            k_max_required += 50\n",
    "\n",
    "\n",
    "mintime_mult_sa_sample(10, 2.280829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mintime_mult_sarandom_sample(n, bound):\n",
    "    k_max_required = 1\n",
    "    while True: \n",
    "        samp = mult_simulated_anneal_random(samp_size, k_max_required, n)\n",
    "        sum = 0\n",
    "        for run in samp: \n",
    "            sum += run[0]\n",
    "        runavg = sum / len(samp)\n",
    "        print(runavg)\n",
    "        if runavg > bound: \n",
    "            return k_max_required\n",
    "        else: \n",
    "            k_max_required += 50\n",
    "\n",
    "\n",
    "mintime_mult_sarandom_sample(10, 2.280829)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Test: \n",
    "\n",
    "Just come code to experiment with changing the hyperparameters (initial temperature, cooling schedule, etc) of the simulated annealing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "single_run = False\n",
    "\n",
    "for t_i in tqdm_notebook([1, 5, 10], desc='Initial Temp'):\n",
    "    for t_rate in tqdm_notebook(np.linspace(0.60, 0.99, 40), desc='Cooling Schedule', leave = False):\n",
    "        for greedy_threshold in tqdm_notebook([0.6], desc='Greedy Threshold', leave = False):\n",
    "            temp_initial = t_i\n",
    "            temp_rate = t_rate\n",
    "            threshold = greedy_threshold\n",
    "            samp = mult_simulated_anneal_random(samp_size, 500, 7)\n",
    "            sum = 0\n",
    "            for run in samp: \n",
    "                sum += run[0]\n",
    "            runavg = sum / len(samp)\n",
    "            list.append([t_i, t_rate, greedy_threshold, runavg])\n",
    "            print(runavg)\n",
    "\n",
    "hp_df = pd.DataFrame(list, columns = ['t_initial', 't_rate', 'greedy_threshold', 'result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['NumH'] == 8].nlargest(35, 'Avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.nlargest(20, 'result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['NumH'] == 7].nlargest(35, 'Avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "sns.distplot(rand_df.loc[rand_df['k_max'] == 900]['runmax']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1, 100, 100).append(np.linspace(102, 150, 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_max_range = []\n",
    "total_k_max = 0\n",
    "for i in range(100): \n",
    "    k_max_range.append(i)\n",
    "    total_k_max += i\n",
    "\n",
    "for i in range(25): \n",
    "    k_max_range.append(100 + i*2)\n",
    "    total_k_max += 100 + i*2\n",
    "    \n",
    "for i in range(25): \n",
    "    k_max_range.append(150 + i*4)\n",
    "    total_k_max += 150 + i*4\n",
    "\n",
    "for i in range(25):\n",
    "    k_max_range.append(250 + i*8)\n",
    "    total_k_max += 250 + i*8\n",
    "\n",
    "for i in range(25):\n",
    "    k_max_range.append(450 + i*16)\n",
    "    total_k_max += 450 + i*16\n",
    "    \n",
    "print(k_max_range)\n",
    "print(total_k_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
